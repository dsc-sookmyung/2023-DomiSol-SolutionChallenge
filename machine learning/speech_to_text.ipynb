{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Google Cloud Speech API sample application using the streaming API.\n",
    "NOTE: This module requires the dependencies `pyaudio` and `termcolor`.\n",
    "To install using pip:\n",
    "    pip install pyaudio\n",
    "    pip install termcolor\n",
    "Example usage:\n",
    "    python transcribe_streaming_infinite.py\n",
    "\"\"\"\n",
    "\n",
    "# [START speech_transcribe_infinite_streaming]\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from google.cloud import speech\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "\n",
    "# Audio recording parameters\n",
    "STREAMING_LIMIT = 1200000  # 4 minutes * 5 = 20minutes\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "RED = \"\\033[0;31m\"\n",
    "GREEN = \"\\033[0;32m\"\n",
    "YELLOW = \"\\033[0;33m\"\n",
    "\n",
    "\n",
    "def get_current_time():\n",
    "    \"\"\"Return Current Time in MS.\"\"\"\n",
    "\n",
    "    return int(round(time.time() * 1000))\n",
    "\n",
    "\n",
    "class ResumableMicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self, rate, chunk_size):\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self.start_time = get_current_time()\n",
    "        self.restart_counter = 0\n",
    "        self.audio_input = []\n",
    "        self.last_audio_input = []\n",
    "        self.result_end_time = 0\n",
    "        self.is_final_end_time = 0\n",
    "        self.final_request_end_time = 0\n",
    "        self.bridging_offset = 0\n",
    "        self.last_transcript_was_final = False\n",
    "        self.new_stream = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    # api와 오디오 스트리밍 연동. api에 오디오 전송하는 함수\n",
    "    def generator(self):\n",
    "        \"\"\"Stream Audio from microphone to API and to local buffer\"\"\"\n",
    "        \n",
    "        # _buff Q에서 데이터 가져오는 동안은 무한루프\n",
    "        while not self.closed:\n",
    "            \n",
    "            # 오디오 추가하는 배열\n",
    "            data = []\n",
    "\n",
    "            if self.new_stream and self.last_audio_input:\n",
    "\n",
    "                # 마이크로 얻은 오디오 스트림의 길이를 STREAMING_LIMIT로 나눔\n",
    "                chunk_time = STREAMING_LIMIT / len(self.last_audio_input)\n",
    "\n",
    "                if chunk_time != 0:\n",
    "\n",
    "                    if self.bridging_offset < 0:\n",
    "                        self.bridging_offset = 0\n",
    "\n",
    "                    if self.bridging_offset > self.final_request_end_time:\n",
    "                        self.bridging_offset = self.final_request_end_time\n",
    "\n",
    "                    chunks_from_ms = round(\n",
    "                        (self.final_request_end_time - self.bridging_offset)\n",
    "                        / chunk_time\n",
    "                    )\n",
    "\n",
    "                    self.bridging_offset = round(\n",
    "                        (len(self.last_audio_input) - chunks_from_ms) * chunk_time\n",
    "                    )\n",
    "\n",
    "                    for i in range(chunks_from_ms, len(self.last_audio_input)):\n",
    "                        data.append(self.last_audio_input[i])\n",
    "\n",
    "                self.new_stream = False\n",
    "\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            self.audio_input.append(chunk)\n",
    "\n",
    "            if chunk is None:\n",
    "                return\n",
    "            \n",
    "            # 데이터에 청크 추가\n",
    "            data.append(chunk)\n",
    "            \n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                    self.audio_input.append(chunk)\n",
    "                \n",
    "                # 큐가 비면 종료\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "    \n",
    "            # binary 형식으로 반환해서 generator()을 호출한 함수로 data 넘겨줌\n",
    "            yield b\"\".join(data)\n",
    "            \n",
    "# txt 파일로 저장\n",
    "def save_transcription_to_file(transcript):\n",
    "    with open(\"transcript.txt\", \"a\") as f:\n",
    "        f.write(transcript + \"\\n\")\n",
    "\n",
    "\n",
    "# 비속어 리스트(직접 추가 중)\n",
    "def extract_slang(audio):\n",
    "#     transcript = r.recognize_google(audio, language='ko-KR')\n",
    "    slang_words = [\"개\", \"존버\", \"노잼\", \"존맛\", \"존나\", \"헐\", \"쌉\", \"킹받네\", \"시발\", \"개새끼\", \"빡치네\", \"병신\"]\n",
    "    for word in slang_words:\n",
    "        if word in audio:\n",
    "            print(f\"ALERT: Slang word '{word}' detected at {time.strftime('%H:%M:%S')}\")\n",
    "    return\n",
    "# return None\n",
    "\n",
    "\n",
    "def listen_print_loop(responses, stream):\n",
    "\n",
    "    for response in responses:\n",
    "\n",
    "        if get_current_time() - stream.start_time > STREAMING_LIMIT:\n",
    "            stream.start_time = get_current_time()\n",
    "            break\n",
    "\n",
    "        if not response.results:\n",
    "            continue\n",
    "\n",
    "        result = response.results[0]\n",
    "\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "\n",
    "        transcript = result.alternatives[0].transcript\n",
    "\n",
    "        result_seconds = 0\n",
    "        result_micros = 0\n",
    "\n",
    "        if result.result_end_time.seconds:\n",
    "            result_seconds = result.result_end_time.seconds\n",
    "\n",
    "        if result.result_end_time.microseconds:\n",
    "            result_micros = result.result_end_time.microseconds\n",
    "\n",
    "        stream.result_end_time = int((result_seconds * 1000) + (result_micros / 1000))\n",
    "\n",
    "        corrected_time = (\n",
    "            stream.result_end_time\n",
    "            - stream.bridging_offset\n",
    "            + (STREAMING_LIMIT * stream.restart_counter)\n",
    "        )\n",
    "        # Display interim results, but with a carriage return at the end of the\n",
    "        # line, so subsequent lines will overwrite them.\n",
    "\n",
    "        # 처리된 결과가 최종 결과이면\n",
    "        if result.is_final:\n",
    "\n",
    "            sys.stdout.write(GREEN)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\n\")\n",
    "\n",
    "            stream.is_final_end_time = stream.result_end_time\n",
    "            stream.last_transcript_was_final = True\n",
    "\n",
    "            # Exit recognition if any of the transcribed phrases could be\n",
    "            # one of our keywords.\n",
    "            if re.search(r\"\\b(그만|녹음 종료)\\b\", transcript, re.I):\n",
    "                save_transcription_to_file(transcript)\n",
    "                sys.stdout.write(YELLOW)\n",
    "                sys.stdout.write(\"Exiting...\\n\")\n",
    "                stream.closed = True\n",
    "                return\n",
    "\n",
    "        else:\n",
    "            sys.stdout.write(RED)\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            sys.stdout.write(str(corrected_time) + \": \" + transcript + \"\\r\")\n",
    "            extract_slang(transcript)\n",
    "            stream.last_transcript_was_final = False\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"start bidirectional streaming from microphone input to speech API\"\"\"\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        language_code=\"ko-KR\", # 한국어\n",
    "        max_alternatives=1,\n",
    "        profanity_filter=True # 비속어 감지 --> 작동안함\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    mic_manager = ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE)\n",
    "    print(mic_manager.chunk_size)\n",
    "    sys.stdout.write(YELLOW)\n",
    "    sys.stdout.write('\\nListening, say \"그만\" or \"녹음 종료\" to stop.\\n\\n')\n",
    "    sys.stdout.write(\"End (ms)       Transcript Results/Status\\n\")\n",
    "    sys.stdout.write(\"=====================================================\\n\")\n",
    "\n",
    "    with mic_manager as stream:\n",
    "\n",
    "        while not stream.closed:\n",
    "            sys.stdout.write(YELLOW)\n",
    "            sys.stdout.write(\n",
    "                \"\\n\" + str(STREAMING_LIMIT * stream.restart_counter) + \": NEW REQUEST\\n\"\n",
    "            )\n",
    "\n",
    "            stream.audio_input = []\n",
    "            audio_generator = stream.generator()\n",
    "\n",
    "            requests = (\n",
    "                speech.StreamingRecognizeRequest(audio_content=content)\n",
    "                for content in audio_generator\n",
    "            )\n",
    "\n",
    "            responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "            # Now, put the transcription responses to use.\n",
    "            listen_print_loop(responses, stream)\n",
    "\n",
    "            if stream.result_end_time > 0:\n",
    "                stream.final_request_end_time = stream.is_final_end_time\n",
    "            stream.result_end_time = 0\n",
    "            stream.last_audio_input = []\n",
    "            stream.last_audio_input = stream.audio_input\n",
    "            stream.audio_input = []\n",
    "            stream.restart_counter = stream.restart_counter + 1\n",
    "\n",
    "            if not stream.last_transcript_was_final:\n",
    "                sys.stdout.write(\"\\n\")\n",
    "            stream.new_stream = True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n",
    "\n",
    "# [END speech_transcribe_infinite_streaming]\n",
    "# 최종 결과 = 녹색 / 중간 = 적색 / 종료 감지 = 노랑"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
